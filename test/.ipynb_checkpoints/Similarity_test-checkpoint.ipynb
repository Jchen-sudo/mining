{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 流量间统计特征啥的相似度\n",
    "\n",
    "## ciciflower特征数据解读\n",
    "\n",
    "这里可以人工把特征分类一下，去除不需要的特征。\n",
    "\n",
    "```\n",
    "（1）fl_dur - - > 流持续时间\n",
    "（2）tot_fw_pk（流出方向？） - - > 在正向上包的数量\n",
    "（3）tot_bw_pk - - > 在反向上包的数量\n",
    "（4）tot_l_fw_pkt - - > 正向数据包的总大小\n",
    "（5）fw_pkt_l_max - - > 包在正向上的最大大小\n",
    "（6）fw_pkt_l_min - - > 包在正向上的最小大小\n",
    "（7）fw_pkt_l_avg - - > 数据包在正向的平均大小\n",
    "（8）fw_pkt_l_std - - > 数据包正向标准偏差大小\n",
    "（9）Bw_pkt_l_max - - > 包在反向上的最大大小\n",
    "（10）Bw_pkt_l_min - - > 包在反向上的最小大小\n",
    "（11）Bw_pkt_l_avg - - > 数据包在反向的平均大小\n",
    "（12）Bw_pkt_l_std - - > 数据包反向标准偏差大小\n",
    "（13）fl_byt_sv - - > 流字节率，即每秒传输的数据包字节数\n",
    "（14）fl_pkt_s - - > 流包率，即每秒传输的数据包数\n",
    "（15）fl_iat_avg - - > 两个流之间的平均时间\n",
    "（16）fl_iat_std - - > 两个流之间标准差\n",
    "（17）fl_iat_max - - > 两个流之间的最大时间\n",
    "（18）fl_iat_minv - - > 两个流之间的最小时间\n",
    "（19）fw_iat_tot - - > 在正向发送的两个包之间的总时间\n",
    "（20）fw_iat_avg - - > 在正向发送的两个包之间的平均时间\n",
    "（21）fw_iat_std - - > 在正向发送的两个数据包之间的标准偏差时间\n",
    "（22）fw_iat_max - - > 在正向发送的两个包之间的最大时间\n",
    "（23）fw_iat_min - - > 在正向发送的两个包之间的最小时间\n",
    "（24）bw_iat_tot - - > 反向发送的两个包之间的总时间\n",
    "（25）bw_iat_avg - - > 反向发送的两个数据包之间的平均时间\n",
    "（26）bw_iat_std - - > 反向发送的两个数据包之间的标准偏差时间\n",
    "（27）bw_iat_max - - > 反向发送的两个包之间的最大时间\n",
    "（28）bw_iat_min - - > 反向发送的两个包之间的最小时间\n",
    "（29）fw_psh_flag - - > 在正向传输的数据包中设置PSH标志的次数(UDP为0)\n",
    "（30）bw_psh_flag - - > 在反向传输的数据包中设置PSH标志的次数(UDP为0)\n",
    "（31）fw_urg_flag - - > 在正向传输的数据包中设置URG标志的次数(UDP为0)\n",
    "（32）bw_urg_flag - - > 反方向数据包中设置URG标志的次数(UDP为0)\n",
    "（33）fw_hdr_len - - > 用于前向方向上的包头的总字节数\n",
    "（34）bw_hdr_len - - > 用于后向方向上的包头的总字节数\n",
    "（35）fw_pkt_s - - > 每秒前向包的数量\n",
    "（36）bw_pkt_s - - > 每秒后向包的数量\n",
    "（37）pkt_len_min - - > 流的最小长度\n",
    "（38）pkt_len_max - - > 流的最大长度\n",
    "（39）pkt_len_avg - - > 流的平均长度\n",
    "（40）pkt_len_std - - > 流长度的方差\n",
    "（41）pkt_len_va - - > 最小包到达间隔时间\n",
    "（42）fin_cnt - - > 带有FIN的包数量\n",
    "（43）syn_cnt - - > 带有SYN的包数量\n",
    "（44）rst_cnt - - > 带有RST的包数量\n",
    "（45）pst_cnt - - > 带有PUSH的包数量\n",
    "（46）ack_cnt - - > 带有 ACK的包数量\n",
    "（47）urg_cnt - - > 带有URG的包数量\n",
    "（48）cwe_cnt - - > 带有CWE的包数量\n",
    "（49）ECE - - > 带有ECE的包数量\n",
    "（50）down_up_ratio - - > 下载和上传的比例\n",
    "（51）pkt_size_avg - - > 数据包的平均大小\n",
    "（52）fw_seg_avg - - > 观察到的前向方向上数据包的平均大小\n",
    "（53）bw_seg_avg - - > 观察到的后向方向上数据包的平均大小\n",
    "（54）fw_byt_blk_avg - - > 在正向上的平均字节数块速率\n",
    "（55）fw_pkt_blk_avg - - > 在正向方向上数据包的平均数量\n",
    "（56）fw_blk_rate_avg - - > 在正向方向上平均bulk速率\n",
    "（57）bw_byt_blk_avg - - > 在反向上的平均字节数块速率\n",
    "（58）bw_pkt_blk_avg - - > 在反向方向上数据包的平均数量\n",
    "（59）bw_blk_rate_avg - - > 在反向方向上平均bulk速率\n",
    "（60）subfl_fw_pk - - > 在正向子流中包的平均数量\n",
    "（61）subfl_fw_byt - - > 子流在正向中的平均字节数\n",
    "（62）subfl_bw_pkt - - > 反向子流中数据包的平均数量\n",
    "（63）subfl_bw_byt - - > 子流在反向中的平均字节数\n",
    "（64）fw_win_byt - - > 在正向的初始窗口中发送的字节数\n",
    "（65）bw_win_byt - - > 在反向的初始窗口中发送的字节数\n",
    "（66）Fw_act_pkt - - > 在正向方向上具有至少1字节TCP数据有效负载的包\n",
    "（67）fw_seg_min - - > 在正方向观察到的最小segment尺寸\n",
    "（68）atv_avg - - > 流在空闲之前处于活动状态的平均时间\n",
    "（69）atv_std - - > 流在空闲之前处于活动状态的标准偏差时间\n",
    "（70）atv_max - - > 流在空闲之前处于活动状态的最大时间\n",
    "（71）atv_min - - > 流空闲前激活的最小时间\n",
    "（72）idl_avg - - > 流在激活之前空闲的平均时间\n",
    "（73）idl_std - - > 流量在激活前处于空闲状态的标准偏差时间\n",
    "（74）idl_max - - > 流在激活之前空闲的最大时间\n",
    "（75）idl_min - - > 流在激活之前空闲的最小时间\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取特征数据\n",
    "\n",
    "import csv\n",
    "\n",
    "with open(r'../data/csv/XMR_1.8K.pcap_Flow_CIC.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "\n",
    "    headers = next(reader)\n",
    "    # print(headers)\n",
    "    rows1 = [row[7:83] for row in reader] # 取8~83列\n",
    "\n",
    "\n",
    "with open(r'../data/csv/WhiteStream/Steam.exe_21688.pcap_Flow.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    next(reader)\n",
    "    rows2 = [row[7:83] for row in reader] # 取8~83列\n",
    "\n",
    "\n",
    "rows = rows1 + rows2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先使用标准化的方法将数据集标准化，去除量纲等的影响\n",
    "\n",
    "归一化和标准化的区别：归一化是将样本的特征值转换到同一量纲下把数据映射到[0,1]或者[-1, 1]区间内，仅由变量的极值决定，因区间放缩法是归一化的一种。标准化是依照特征矩阵的列处理数据，其通过求z-score的方法，转换为标准正态分布，和整体样本分布相关，每个样本点都能对标准化产生影响。它们的相同点在于都能取消由于量纲不同引起的误差；都是一种线性变换，都是对向量X按照比例压缩再进行平移。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.63163356 -1.15771329 -0.85574803 ...  1.80770052  1.23749736\n",
      "  -0.57910442]\n",
      " [ 0.70731722 -0.32085197  0.00739184 ...  0.86498231  0.46245307\n",
      "  -0.0558528 ]\n",
      " [ 0.28167906  0.79496312  1.15824501 ... -0.31138069 -0.57333102\n",
      "  -0.40490956]\n",
      " ...\n",
      " [-1.89197989 -0.59980574 -0.28032145 ... -1.65320964 -0.63371144\n",
      "   1.44438617]\n",
      " [-0.96039413 -0.32085197  1.15824501 ... -1.65320964  1.22259945\n",
      "   3.94269103]\n",
      " [-1.88624503  0.23705558  0.29510513 ... -1.65320964 -0.63372647\n",
      "   1.44436595]]\n",
      "[[0.92362539 0.15384615 0.16666667 ... 0.72991356 0.9633386  0.09077062]\n",
      " [0.94373166 0.26923077 0.29166667 ... 0.53109222 0.7629287  0.19137268]\n",
      " [0.83065581 0.42307692 0.45833333 ... 0.28299468 0.49509706 0.12426189]\n",
      " ...\n",
      " [0.25319737 0.23076923 0.25       ... 0.         0.47948398 0.47981353]\n",
      " [0.50068424 0.26923077 0.45833333 ... 0.         0.95948632 0.96014578]\n",
      " [0.2547209  0.34615385 0.33333333 ... 0.         0.47948009 0.47980964]]\n"
     ]
    }
   ],
   "source": [
    "# 标准化\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "rows_standscaler = StandardScaler().fit_transform(rows)\n",
    "rows_minmaxscaler = MinMaxScaler().fit_transform(rows)\n",
    "print(rows_standscaler)\n",
    "print(rows_minmaxscaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 降维\n",
    "\n",
    "特征值的数量比较多，部分特征间有一定的相关度，如：\n",
    "\n",
    "- （2）tot_fw_pk（流出方向？） - - > 在正向上包的数量\n",
    "- （4）tot_l_fw_pkt - - > 正向数据包的总大小\n",
    "\n",
    "所以标准化后可以适应降维方法对数据进行降维。\n",
    "\n",
    "降维的方法有：\n",
    "\n",
    "- 主成分分析\n",
    "- 奇异值分解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可以PCA降维后再计算相似度，这先空着"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 相似度计算\n",
    "\n",
    "在做分类时，常常需要估算不同样本之间的相似性度量（Similarity Measurement），这时通常采用的方法就是计算样本间的“距离”（distance）。采用什么样的方法计算距离是很讲究的，甚至关系到分类的正确与否。\n",
    "\n",
    "一些常用的相似度计算方法：\n",
    "- 欧式距离\n",
    "- 曼哈顿距离\n",
    "- 切比雪夫距离\n",
    "- 闵可夫斯基距离\n",
    "- 标准化欧氏距离\n",
    "- 马氏距离\n",
    "- 夹角余弦\n",
    "- 汉明距离\n",
    "- 杰卡德距离&杰卡德相似系数\n",
    "- 相关系数&相关距离\n",
    "- 信息熵\n",
    "\n",
    "参考：\n",
    "\n",
    "https://blog.csdn.net/u012684062/article/details/73395764\n",
    "https://zhuanlan.zhihu.com/p/55493039\n",
    "\n",
    "**DTW**\n",
    "\n",
    "描述两个序列之间的相似性，欧氏距离是一种十分简单且直观的方法，但对于序列之间的情况，计算欧氏距离得到的结果会比实际的最小距离大很多。对于序列间的相似度有 dynamic time warping(DTW) \n",
    "\n",
    "参考：https://zhuanlan.zhihu.com/p/117634492\n",
    "\n",
    "**余弦相似度**\n",
    "\n",
    "余弦相似性通过测量两个向量的夹角的余弦值来度量它们之间的相似性。0度角的余弦值是1，而其他任何角度的余弦值都不大于1；并且其最小值是-1。从而两个向量之间的角度的余弦值确定两个向量是否大致指向相同的方向。两个向量有相同的指向时，余弦相似度的值为1；两个向量夹角为90°时，余弦相似度的值为0；两个向量指向完全相反的方向时，余弦相似度的值为-1。这结果是与向量的长度无关的，仅仅与向量的指向方向相关。余弦相似度通常用于正空间，因此给出的值为-1到1之间。\n",
    "\n",
    "注意这上下界对任何维度的向量空间中都适用，而且余弦相似性最常用于高维正空间。例如在信息检索中，每个词项被赋予不同的维度，而一个维度由一个向量表示，其各个维度上的值对应于该词项在文档中出现的频率。余弦相似度因此可以给出两篇文档在其主题方面的相似度。\n",
    "\n",
    "另外，它通常用于文本挖掘中的文件比较。此外，在数据挖掘领域中，会用到它来度量集群内部的凝聚力。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "相似度： [[0.73187616]]\n",
      "相似度： [[-0.22668392]]\n"
     ]
    }
   ],
   "source": [
    "# 相似度计算\n",
    "# 因为可能有潜在的正比关系，所以可以用余弦相似度试试\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "result=cosine_similarity(rows_standscaler[0].reshape(1,-1), rows_standscaler[1].reshape(1,-1))\n",
    "print('相似度：', result)\n",
    "\n",
    "result=cosine_similarity(rows_standscaler[0].reshape(1,-1), rows_standscaler[-1].reshape(1,-1))\n",
    "print('相似度：', result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试发现，同类的相似度比较高，异类的相似度比较低\n",
    "\n",
    "但只是实验性的测试，需要通过理论进一步的优化\n",
    "\n",
    "# 仍需要做的\n",
    "\n",
    "划分训练集测试集验证集，统计方法验证、同类相似度平均值方差、异类相似度平均值方差等，验证可行性\n",
    "\n",
    "手工降维与机器学习降维相结合\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "14db40aade9d7ecdc25b6df19d52ec9dfd450d2c598495855312ffa5207b95bf"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
